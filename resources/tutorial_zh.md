## æ•°æ®é›†è¯„æµ‹æ•™ç¨‹

## ğŸš€ å¦‚ä½•è¿›è¡Œæµ‹è¯•
å¦‚æœéœ€è¦åœ¨è‡ªå·±çš„ huggingface æ ¼å¼çš„æ¨¡å‹ä¸Šè¿›è¡Œæµ‹è¯•çš„è¯ï¼Œæ€»çš„æ­¥éª¤åˆ†ä¸ºå¦‚ä¸‹å‡ æ­¥:
1. ç¼–å†™ Model çš„ loader å‡½æ•°
2. ç¼–å†™ Model çš„ context_builder å‡½æ•°
3. æ³¨å†Œæ¨¡å‹åˆ°é…ç½®æ–‡ä»¶ä¸­
4. æ‰§è¡Œæµ‹è¯•è„šæœ¬
å¦‚æœæ¨¡å‹åœ¨åŠ è½½è¿›æ¥åä¸éœ€è¦ç‰¹æ®Šçš„å¤„ç†ï¼Œè€Œä¸”è¾“å…¥ä¹Ÿä¸éœ€è¦è½¬æ¢ä¸ºç‰¹å®šçš„æ ¼å¼ï¼ˆe.g. chatml æ ¼å¼æˆ–è€…å…¶ä»–çš„ human-bot æ ¼å¼ï¼‰ï¼Œè¯·ç›´æ¥è·³è½¬åˆ°ç¬¬å››æ­¥ç›´æ¥å‘èµ·æµ‹è¯•ã€‚

#### 1. ç¼–å†™ loader å‡½æ•°
å¦‚æœæ¨¡å‹åœ¨åŠ è½½è¿›æ¥è¿˜éœ€è¦åšä¸€äº›é¢å¤–çš„å¤„ç†ï¼ˆe.g. tokenizer è°ƒæ•´ï¼‰ï¼Œéœ€è¦å» `src.context_builder.context_builder_family.py` ä¸­ç»§æ‰¿ `ModelAndTokenizerLoader` ç±»æ¥è¦†å†™å¯¹åº”çš„ `load_model` å’Œ `load_tokenizer` å‡½æ•°ï¼Œå…·ä½“å¯ä»¥å‚ç…§ä»¥ä¸‹ç¤ºä¾‹ï¼š
```python
class QwenModelAndTokenizerLoader(ModelAndTokenizerLoader):
    def __init__(self):
        super().__init__()
        pass
      
    def load_model(self, model_path: str):
        model = super().load_model(model_path)
        model.generation_config = GenerationConfig.from_pretrained(model_path)
        return model
    
    def load_tokenizer(self, model_path: str):
        tokenizer = super().load_tokenizer(model_path)
    
        # read generation config
        with open(model_path + '/generation_config.json', 'r') as f:
        generation_config = json.load(f)
        tokenizer.pad_token_id = generation_config['pad_token_id']
        tokenizer.eos_token_id = generation_config['eos_token_id']
        return tokenizer
```

#### 2. ç¼–å†™ Model çš„ context_builder å‡½æ•°
å¦‚æœè¾“å…¥éœ€è¦è½¬æ¢ä¸ºç‰¹å®šçš„æ ¼å¼ï¼ˆe.g. chatml æ ¼å¼æˆ–è€…å…¶ä»–çš„ human-bot æ ¼å¼ï¼‰ï¼Œåˆ™éœ€è¦å» `src.context_builder.context_builder_family` ä¸­ç»§æ‰¿ ContextBuilder ç±»æ¥è¦†å†™ make_context å‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°æ˜¯ç”¨æ¥å°†è¾“å…¥è½¬æ¢æ ¼å¼ä¸ºå¯¹åº”éœ€è¦çš„è¾“å‡ºçš„ï¼Œä¸€ä¸ªç¤ºä¾‹å¦‚ä¸‹ï¼š
```python
class QwenChatContextBuilder(ContextBuilder):
    def __init__(self):
        super().__init__()
    
    def make_context(
        self,
        model,
        tokenizer, 
        query: str,
        system: str = "you are a helpful assistant"
    ):
      '''
  model: PretrainedModel
  tokenizer: PretrainedTokenzier
  query: Input string
  system: System prompt if needed
  '''
        im_start, im_end = "<|im_start|>", "<|im_end|>"
        im_start_tokens = [tokenizer.im_start_id]
        im_end_tokens = [tokenizer.im_end_id]
        nl_tokens = tokenizer.encode("\n")

        def _tokenize_str(role, content):
            return f"{role}\n{content}", tokenizer.encode(
                role, allowed_special=set()
            ) + nl_tokens + tokenizer.encode(content, allowed_special=set())

        system_text, system_tokens_part = _tokenize_str("system", system)
        system_tokens = im_start_tokens + system_tokens_part + im_end_tokens

        raw_text = ""
        context_tokens = []

        context_tokens = system_tokens + context_tokens
        raw_text = f"{im_start}{system_text}{im_end}" + raw_text
        context_tokens += (
            nl_tokens
            + im_start_tokens
            + _tokenize_str("user", query)[1]
            + im_end_tokens
            + nl_tokens
            + im_start_tokens
            + tokenizer.encode("assistant")
            + nl_tokens
        )
        raw_text += f"\n{im_start}user\n{query}{im_end}\n{im_start}assistant\n"
        return raw_text, context_tokens
```

#### 3. æ³¨å†Œæ¨¡å‹åˆ°é…ç½®æ–‡ä»¶ä¸­
å» conf ä¸­çš„ `model_conf.json`ï¼Œæ³¨å†Œå¯¹åº”çš„æ¨¡å‹åå’Œè¿™ä¸ªæ¨¡å‹å°†è¦ä½¿ç”¨çš„ loader å’Œ context_builderï¼Œå…¶ä¸­ loader å’Œ context_builder å†™ç¬¬ä¸€æ­¥å’Œç¬¬äºŒæ­¥ä¸­è‡ªå®šä¹‰çš„ç±»åå°±å¯ä»¥ï¼Œç¤ºä¾‹å¦‚ä¸‹ï¼š
```json
{
  "Qwen-Chat": {
  "loader": "QwenModelAndTokenizerLoader",
  "context_builder": "QwenChatContextBuilder"
  }
}
```


#### 4. æ‰§è¡Œæµ‹è¯•è„šæœ¬
ç›´æ¥è¿è¡Œä»¥ä¸‹ä»£ç å‘èµ·æµ‹è¯•
```Bash
# model_path: è¦æµ‹è¯•çš„æ¨¡å‹è·¯å¾„
# model_name: æ¨¡å‹é…ç½®æ–‡ä»¶å¯¹åº”çš„æ¨¡å‹å‘½åï¼Œé»˜è®¤ä¸º Default ï¼Œä»£è¡¨èµ°é»˜è®¤çš„ loader å’Œ context_builder
# model_conf_path: æ¨¡å‹é…ç½®æ–‡ä»¶çš„åœ°å€ï¼Œä¸€èˆ¬å°±ä¸º conf è·¯å¾„ä¸‹çš„ devopseval_dataset_fp.json
# eval_dataset_list: è¦æµ‹è¯•çš„æ•°æ®é›†åç§°ï¼Œé»˜è®¤ allï¼Œå…¨éƒ¨æµ‹è¯•ï¼Œå¦‚æœéœ€è¦æµ‹è¯•å•ä¸ªæˆ–è€…å¤šä¸ªï¼Œç”¨ # ç¬¦å·é“¾æ¥ï¼Œç¤ºä¾‹ï¼šdataset1#dataset2
# eval_dataset_fp_conf_path: æ•°æ®é›†é…ç½®åœ°å€
# eval_dataset_type: æµ‹è¯•å“ªç§ç±»å‹ï¼Œåªæ”¯æŒé»˜è®¤ test ç±»å‹çš„æµ‹è¯•é›†
# data_path: è¯„æµ‹æ•°æ®é›†åœ°å€ï¼Œå¡«å†™ä¸‹è½½æ•°æ®é›†åçš„åœ°å€å°±å¯ä»¥
# k_shot: æ”¯æŒ 0-5ï¼Œä»£è¡¨ few-shot ä¼šç»™æ¨¡å‹å‰ç¼€åŠ çš„ç¤ºä¾‹æ•°é‡

  
python src/run_eval.py \
--model_path path_to_model \
--model_name model_name_in_conf \
--model_conf_path path_to_model_conf \
--eval_dataset_list all \
--eval_dataset_fp_conf_path path_to_dataset_conf \
--eval_dataset_type test \
--data_path path_to_downloaded_devops_eval_data \
--k_shot 0
```

ä¸¾ä¸ªğŸŒ°ï¼šæ¯”å¦‚è¯„æµ‹æ•°æ®é›†ä¸‹è½½åˆ°äº† `folder1`ï¼Œä»£ç æ”¾åœ¨äº† `folder2`ï¼Œæ¨¡å‹åœ¨ `folder3`ï¼Œæ¨¡å‹ä¸éœ€è¦è‡ªå®šä¹‰ loader å’Œ context_builderï¼Œéœ€è¦æµ‹è¯•æ‰€æœ‰çš„æ•°æ®é›†çš„ zero-shot å¾—åˆ†ï¼Œé‚£å¯ä»¥æŒ‰ç…§ä»¥ä¸‹è„šæœ¬å‘èµ·æµ‹è¯•ï¼š
```Bash
python folder2/src/run_eval.py \
--model_path folder3 \
--model_name Default \
--model_conf_path folder1/conf/model_conf.json \
--eval_dataset_list all \
--eval_dataset_fp_conf_path folder1/conf/devopseval_dataset_fp.json \
--eval_dataset_type test \
--data_path folder2 \
--k_shot 0
```
<br>