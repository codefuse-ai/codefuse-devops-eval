# DevOps-Eval
A DevOps Domain Knowledge Evaluation Benchmark for Large Language Models

<p align="center">
  ğŸ¤— <a href="https://huggingface.co/datasets/DevOps-Eval/devopseval-exam" target="_blank">Hugging Face</a> â€¢ â¬ <a href="#data" target="_blank">æ•°æ®</a> â€¢ ğŸ“– <a href="resources/tutorial.md" target="_blank">æ•™ç¨‹</a>
  <br>
  <a href="https://github.com/codefuse-ai/codefuse-devops-eval/blob/main/README.md"> English</a> | <a href="https://github.com/codefuse-ai/codefuse-devops-eval/blob/main/README_zh.md"> ä¸­æ–‡
</p>

DevOps-Eval is a comprehensive evaluation suite specifically designed for foundation models in the DevOps field. It consists of xxxx multi-choice questions spanning 8 diverse disciplines, as shown below.

We hope DevOps-Eval could help developers, especially in the DevOps field, track the progress and analyze the important strengths/shortcomings of their models.

<img src="images/devops_diagram_zh.jpg" style="zoom: 80%;" >


## æ›´æ–°

* **[2023.09.30]** DevOps-Eval...
<br>
<br>

## ç›®å½•

- [æ’è¡Œæ¦œ](#æ’è¡Œæ¦œ)
- [éªŒè¯é›†ç»“æœ](#éªŒè¯é›†ç»“æœ)
- [æ•°æ®](#æ•°æ®)
- [å¦‚ä½•è¿›è¡Œæµ‹è¯•](#å¦‚ä½•è¿›è¡Œæµ‹è¯•)
- [TODO](#todo)
- [Licenses](#licenses)
- [å¼•ç”¨](#å¼•ç”¨)

## æ’è¡Œæ¦œ
coming soon
<br>
<br>

## éªŒè¯é›†ç»“æœ
coming soon
<br>
<br>

## æ•°æ®
#### ä¸‹è½½
* æ–¹æ³•ä¸€ï¼šä¸‹è½½zipå‹ç¼©æ–‡ä»¶ï¼ˆä½ ä¹Ÿå¯ä»¥ç›´æ¥ç”¨æµè§ˆå™¨æ‰“å¼€ä¸‹é¢çš„é“¾æ¥ï¼‰ï¼š
  ```
  wget https://huggingface.co/datasets/DevOps-Eval/devopseval-exam/resolve/main/data.zip
  ```
  ç„¶åå¯ä»¥ä½¿ç”¨ pandasåŠ è½½æ•°æ®ï¼š

  ```
  import os
  import pandas as pd
  
  File_Dir="devopseval-exam"
  test_df=pd.read_csv(os.path.join(File_Dir,"test","UnitTesting.csv"))
  ```
* æ–¹æ³•äºŒï¼šä½¿ç”¨[Hugging Face datasets](https://huggingface.co/datasets/DevOps-Eval/devopseval-exam)ç›´æ¥åŠ è½½æ•°æ®é›†ã€‚ç¤ºä¾‹å¦‚ä¸‹ï¼š
  ```python
  from datasets import load_dataset
  dataset=load_dataset(r"DevOps-Eval/devopseval-exam",name="UnitTesting")
  
  print(dataset['val'][0])
  # {"id": 1, "question": "å•å…ƒæµ‹è¯•åº”è¯¥è¦†ç›–ä»¥ä¸‹å“ªäº›æ–¹é¢ï¼Ÿ", "A": "æ­£å¸¸è·¯å¾„", "B": "å¼‚å¸¸è·¯å¾„", "C": "è¾¹ç•Œå€¼æ¡ä»¶"ï¼Œ"D": æ‰€æœ‰ä»¥ä¸Šï¼Œ"answer": "D", "explanation": ""}  ```
#### è¯´æ˜
ä¸ºäº†æ–¹ä¾¿ä½¿ç”¨ï¼Œæˆ‘ä»¬å·²ç»æ•´ç†å‡ºäº† 49 ä¸ªç»†åˆ†ç±»åˆ«ä»¥åŠå®ƒä»¬çš„ä¸­è‹±æ–‡åç§°ã€‚å…·ä½“ç»†èŠ‚è¯·æŸ¥çœ‹ [category_mapping.json](https://github.com/codefuse-ai/codefuse-devops-eval/category_mapping.json) ã€‚æ ¼å¼å¦‚ä¸‹ï¼š

```
{
  "UnitTesting.csv": [
    "unit testing",
    "å•å…ƒæµ‹è¯•",
    "TEST"
  ],
  ...
  "file_name":[
  "è‹±æ–‡åç§°",
  "ä¸­æ–‡åç§°",
  "ç±»åˆ«(PLAN,CODE,BUILD,TEST,RELEASE,DEPOLY,OPERATE,MONITORå…«é€‰ä¸€)"
  ]
}
```
æ¯ä¸ªç»†åˆ†ç±»åˆ«ç”±ä¸¤ä¸ªéƒ¨åˆ†ç»„æˆï¼šdev å’Œ testã€‚æ¯ä¸ªç»†åˆ†ç±»åˆ«çš„ dev é›†åŒ…å«äº”ä¸ªç¤ºèŒƒå®ä¾‹ä»¥åŠä¸º few-shot è¯„ä¼°æä¾›çš„è§£é‡Šã€‚è€Œ test é›†åˆ™ç”¨äºæ¨¡å‹è¯„ä¼°ï¼Œå¹¶ä¸”testæ•°æ®å·²åŒ…å«å‡†ç¡®æ ‡ç­¾ã€‚

ä¸‹é¢æ˜¯ dev æ•°æ®çš„ç¤ºä¾‹ï¼Œæ¥è‡ª"ç‰ˆæœ¬æ§åˆ¶"ç»†åˆ†ç±»åˆ«ï¼š
```
id: 1
question: å¦‚ä½•æ‰¾åˆ°Gitç‰¹å®šæäº¤ä¸­å·²æ›´æ”¹çš„æ–‡ä»¶åˆ—è¡¨ï¼Ÿ
A: ä½¿ç”¨å‘½ä»¤ `git diff --name-only SHA`
B: ä½¿ç”¨å‘½ä»¤ `git log --name-only SHA`
C: ä½¿ç”¨å‘½ä»¤ `git commit --name-only SHA`
D: ä½¿ç”¨å‘½ä»¤ `git clone --name-only SHA`
answer: A
explanation: 
åˆ†æåŸå› ï¼š
git diff --name-only SHAå‘½ä»¤ä¼šæ˜¾ç¤ºä¸SHAå‚æ•°å¯¹åº”çš„æäº¤ä¸­å·²ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨ã€‚å‚æ•°--name-onlyè®©å‘½ä»¤åªè¾“å‡ºæ–‡ä»¶åï¼Œè€Œå¿½ç•¥å…¶ä»–ä¿¡æ¯ã€‚å…¶å®ƒé€‰é¡¹ä¸­çš„å‘½ä»¤å¹¶ä¸èƒ½å®ç°æ­¤åŠŸèƒ½ã€‚
```

## å¦‚ä½•è¿›è¡Œæµ‹è¯•
å¦‚æœéœ€è¦åœ¨è‡ªå·±çš„ huggingface æ ¼å¼çš„æ¨¡å‹ä¸Šè¿›è¡Œæµ‹è¯•çš„è¯ï¼Œæ€»çš„æ­¥éª¤åˆ†ä¸ºå¦‚ä¸‹å‡ æ­¥:
1. ç¼–å†™ Model çš„ loader å‡½æ•°
2. ç¼–å†™ Model çš„ context_builder å‡½æ•°
3. æ³¨å†Œæ¨¡å‹åˆ°é…ç½®æ–‡ä»¶ä¸­
4. æ‰§è¡Œæµ‹è¯•è„šæœ¬
å¦‚æœæ¨¡å‹åœ¨åŠ è½½è¿›æ¥åä¸éœ€è¦ç‰¹æ®Šçš„å¤„ç†ï¼Œè€Œä¸”è¾“å…¥ä¹Ÿä¸éœ€è¦è½¬æ¢ä¸ºç‰¹å®šçš„æ ¼å¼ï¼ˆe.g. chatml æ ¼å¼æˆ–è€…å…¶ä»–çš„ human-bot æ ¼å¼ï¼‰ï¼Œè¯·ç›´æ¥è·³è½¬åˆ°ç¬¬å››æ­¥ç›´æ¥å‘èµ·æµ‹è¯•ã€‚

#### 1. ç¼–å†™ loader å‡½æ•°
å¦‚æœæ¨¡å‹åœ¨åŠ è½½è¿›æ¥è¿˜éœ€è¦åšä¸€äº›é¢å¤–çš„å¤„ç†ï¼ˆe.g. tokenizer è°ƒæ•´ï¼‰ï¼Œéœ€è¦å» `src.context_builder.context_builder_family.py` ä¸­ç»§æ‰¿ `ModelAndTokenizerLoader` ç±»æ¥è¦†å†™å¯¹åº”çš„ `load_model` å’Œ `load_tokenizer` å‡½æ•°ï¼Œå…·ä½“å¯ä»¥å‚ç…§ä»¥ä¸‹ç¤ºä¾‹ï¼š
```python
class QwenModelAndTokenizerLoader(ModelAndTokenizerLoader):
    def __init__(self):
        super().__init__()
        pass
      
    def load_model(self, model_path: str):
        model = super().load_model(model_path)
        model.generation_config = GenerationConfig.from_pretrained(model_path)
        return model
    
    def load_tokenizer(self, model_path: str):
        tokenizer = super().load_tokenizer(model_path)
    
        # read generation config
        with open(model_path + '/generation_config.json', 'r') as f:
        generation_config = json.load(f)
        tokenizer.pad_token_id = generation_config['pad_token_id']
        tokenizer.eos_token_id = generation_config['eos_token_id']
        return tokenizer
```

#### 2. ç¼–å†™ Model çš„ context_builder å‡½æ•°
å¦‚æœè¾“å…¥éœ€è¦è½¬æ¢ä¸ºç‰¹å®šçš„æ ¼å¼ï¼ˆe.g. chatml æ ¼å¼æˆ–è€…å…¶ä»–çš„ human-bot æ ¼å¼ï¼‰ï¼Œåˆ™éœ€è¦å» `src.context_builder.context_builder_family` ä¸­ç»§æ‰¿ ContextBuilder ç±»æ¥è¦†å†™ make_context å‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°æ˜¯ç”¨æ¥å°†è¾“å…¥è½¬æ¢æ ¼å¼ä¸ºå¯¹åº”éœ€è¦çš„è¾“å‡ºçš„ï¼Œä¸€ä¸ªç¤ºä¾‹å¦‚ä¸‹ï¼š
```python
class QwenChatContextBuilder(ContextBuilder):
    def __init__(self):
        super().__init__()
    
    def make_context(
        self,
        model,
        tokenizer, 
        query: str,
        system: str = "you are a helpful assistant"
    ):
      '''
  model: PretrainedModel
  tokenizer: PretrainedTokenzier
  query: Input string
  system: System prompt if needed
  '''
        im_start, im_end = "<|im_start|>", "<|im_end|>"
        im_start_tokens = [tokenizer.im_start_id]
        im_end_tokens = [tokenizer.im_end_id]
        nl_tokens = tokenizer.encode("\n")

        def _tokenize_str(role, content):
            return f"{role}\n{content}", tokenizer.encode(
                role, allowed_special=set()
            ) + nl_tokens + tokenizer.encode(content, allowed_special=set())

        system_text, system_tokens_part = _tokenize_str("system", system)
        system_tokens = im_start_tokens + system_tokens_part + im_end_tokens

        raw_text = ""
        context_tokens = []

        context_tokens = system_tokens + context_tokens
        raw_text = f"{im_start}{system_text}{im_end}" + raw_text
        context_tokens += (
            nl_tokens
            + im_start_tokens
            + _tokenize_str("user", query)[1]
            + im_end_tokens
            + nl_tokens
            + im_start_tokens
            + tokenizer.encode("assistant")
            + nl_tokens
        )
        raw_text += f"\n{im_start}user\n{query}{im_end}\n{im_start}assistant\n"
        return raw_text, context_tokens
```

#### 3. æ³¨å†Œæ¨¡å‹åˆ°é…ç½®æ–‡ä»¶ä¸­
å» conf ä¸­çš„ `model_conf.json`ï¼Œæ³¨å†Œå¯¹åº”çš„æ¨¡å‹åå’Œè¿™ä¸ªæ¨¡å‹å°†è¦ä½¿ç”¨çš„ loader å’Œ context_builderï¼Œå…¶ä¸­ loader å’Œ context_builder å†™ç¬¬ä¸€æ­¥å’Œç¬¬äºŒæ­¥ä¸­è‡ªå®šä¹‰çš„ç±»åå°±å¯ä»¥ï¼Œç¤ºä¾‹å¦‚ä¸‹ï¼š
```json
{
  "Qwen-Chat": {
  "loader": "QwenModelAndTokenizerLoader",
  "context_builder": "QwenChatContextBuilder"
  }
}
```


#### 4. æ‰§è¡Œæµ‹è¯•è„šæœ¬
ç›´æ¥è¿è¡Œä»¥ä¸‹ä»£ç å‘èµ·æµ‹è¯•
```Bash
# model_path: è¦æµ‹è¯•çš„æ¨¡å‹è·¯å¾„
# model_name: æ¨¡å‹é…ç½®æ–‡ä»¶å¯¹åº”çš„æ¨¡å‹å‘½åï¼Œé»˜è®¤ä¸º Default ï¼Œä»£è¡¨èµ°é»˜è®¤çš„ loader å’Œ context_builder
# model_conf_path: æ¨¡å‹é…ç½®æ–‡ä»¶çš„åœ°å€ï¼Œä¸€èˆ¬å°±ä¸º conf è·¯å¾„ä¸‹çš„ devopseval_dataset_fp.json
# eval_dataset_list: è¦æµ‹è¯•çš„æ•°æ®é›†åç§°ï¼Œé»˜è®¤ allï¼Œå…¨éƒ¨æµ‹è¯•ï¼Œå¦‚æœéœ€è¦æµ‹è¯•å•ä¸ªæˆ–è€…å¤šä¸ªï¼Œç”¨ # ç¬¦å·é“¾æ¥ï¼Œç¤ºä¾‹ï¼šdataset1#dataset2
# eval_dataset_fp_conf_path: æ•°æ®é›†é…ç½®åœ°å€
# eval_dataset_type: æµ‹è¯•å“ªç§ç±»å‹ï¼Œåªæ”¯æŒé»˜è®¤ test ç±»å‹çš„æµ‹è¯•é›†
# data_path: è¯„æµ‹æ•°æ®é›†åœ°å€ï¼Œå¡«å†™ä¸‹è½½æ•°æ®é›†åçš„åœ°å€å°±å¯ä»¥
# k_shot: æ”¯æŒ 0-5ï¼Œä»£è¡¨ few-shot ä¼šç»™æ¨¡å‹å‰ç¼€åŠ çš„ç¤ºä¾‹æ•°é‡

  
python src/run_eval.py \
--model_path path_to_model \
--model_name model_name_in_conf \
--model_conf_path path_to_model_conf \
--eval_dataset_list all \
--eval_dataset_fp_conf_path path_to_dataset_conf \
--eval_dataset_type test \
--data_path path_to_downloaded_devops_eval_data \
--k_shot 0
```

ä¸¾ä¸ªğŸŒ°ï¼šæ¯”å¦‚è¯„æµ‹æ•°æ®é›†ä¸‹è½½åˆ°äº† `folder1`ï¼Œä»£ç æ”¾åœ¨äº† `folder2`ï¼Œæ¨¡å‹åœ¨ `folder3`ï¼Œæ¨¡å‹ä¸éœ€è¦è‡ªå®šä¹‰ loader å’Œ context_builderï¼Œéœ€è¦æµ‹è¯•æ‰€æœ‰çš„æ•°æ®é›†çš„ zero-shot å¾—åˆ†ï¼Œé‚£å¯ä»¥æŒ‰ç…§ä»¥ä¸‹è„šæœ¬å‘èµ·æµ‹è¯•ï¼š
```Bash
python folder2/src/run_eval.py \
--model_path folder3 \
--model_name Default \
--model_conf_path folder1/conf/model_conf.json \
--eval_dataset_list all \
--eval_dataset_fp_conf_path folder1/conf/devopseval_dataset_fp.json \
--eval_dataset_type test \
--data_path folder2 \
--k_shot 0
```
<br>

## TODO
<br>
<br>

## Licenses

[![MIT license](https://img.shields.io/badge/License-MIT-blue.svg)](https://lbesson.mit-license.org/)

æœ¬é¡¹ç›®éµå¾ª [MIT License](https://lbesson.mit-license.org/).

<br>
<br>

## å¼•ç”¨

å¦‚æœæ‚¨ä½¿ç”¨äº†æˆ‘ä»¬çš„æ•°æ®é›†ï¼Œè¯·å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ã€‚
<br>
<br>
